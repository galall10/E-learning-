{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galall10/E-learning-/blob/main/Copy_of_NTI_Grad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "95ff8231355d469dac978daf3b17fbfe",
            "e2aef9f8af4b4551930af1ac9736c0c6",
            "594bfb9ca0b74215ae51d855cab41543",
            "195ac721cc2943a2bf3d9feb6eff13ce",
            "55e89285237c427e94b4990f3abb72a2",
            "8fea3e7b085646d39fd891752a702f24",
            "48b75d859c8a4b0a91110122a42039f8",
            "c64f5f240f9a499bb791f08b333fcc5d",
            "73a5cae09efb4416b9acd90efdf7a579",
            "3de5d68a4140453b9fa3ede86b3ee03c",
            "7043e8082d3c4d22855b2b49b002c15e",
            "6a4dc9a77ad8447d97680a5eac1cd101",
            "532fa79484184437b316ecacd284b064",
            "a456dfaabf654423aebdc6f2fc2169ba",
            "405b177152704226875e5b5b6c4b0777",
            "0dddacd303364716b932003ca3a2096a",
            "70b9f53c894c419db4225c6c35e74ffd",
            "82ccbf6c819d4c84bd7c912e828e462b",
            "1c3b768ace874bdd9816d52dbb9194d8",
            "2eadb763c06d436bb9dd12dd2c1da453",
            "4c7548a0f98549888e5839cc95e42ae9",
            "aeaa7dcfff6b4507ac1a46f97f36df44",
            "c2c20b7ab813430bafccd70da6e14469"
          ]
        },
        "id": "rxZkvPAWxQQo",
        "outputId": "ad9987c2-3e95-4c83-954a-d6e5f22873f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95ff8231355d469dac978daf3b17fbfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5EP68DvxQQq",
        "outputId": "a9ec2361-e83a-4e08-ad8c-1d3a92507a92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "multi_instance_object_detection_challenge_path = kagglehub.competition_download('multi-instance-object-detection-challenge')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KrgtbOHzf_C",
        "outputId": "df17367b-20ae-44ca-f0e1-e49097c63b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.155)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import os\n",
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmGD0HRBzjAB",
        "outputId": "577d75bd-9496-4682-df1a-7b7e6c1d15f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset configuration file created\n"
          ]
        }
      ],
      "source": [
        "data_yaml = \"\"\"\n",
        "path: /kaggle/input/synthetic-2-real-object-detection-challenge-2/Synthetic to Real Object Detection Challenge 2\n",
        "\n",
        "train:\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/clutter/train/images\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/couch_far_10/train/images\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/far_10_half_clutter/train/images\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/film_grain_10_half_clutter/train/images\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/large_plant_10/train/images\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/no_clutter_10/train/images\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/table_close_10/train/images\n",
        "val:\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/clutter/val/images\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/couch_far_10/val/images\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/far_10_half_clutter/val/images\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/film_grain_10_half_clutter/val/images\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/large_plant_10/val/images\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/no_clutter_10/val/images\n",
        "  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/table_close_10/val/images\n",
        "\n",
        "test: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/TestImages/images\n",
        "\n",
        "nc: 1\n",
        "names: ['soup can']\n",
        "\"\"\"\n",
        "\n",
        "# Save the configuration file\n",
        "with open('data.yaml', 'w') as file:\n",
        "    file.write(data_yaml)\n",
        "\n",
        "print(\"Dataset configuration file created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqgte8UaUvpB",
        "outputId": "f9998b79-0c4a-4350-b5fc-ad8d98170f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking training image paths:\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/clutter/train/images\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/couch_far_10/train/images\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/far_10_half_clutter/train/images\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/film_grain_10_half_clutter/train/images\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/large_plant_10/train/images\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/no_clutter_10/train/images\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/table_close_10/train/images\n",
            "\n",
            "Checking validation image paths:\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/clutter/val/images\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/couch_far_10/val/images\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/far_10_half_clutter/val/images\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/film_grain_10_half_clutter/val/images\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/large_plant_10/val/images\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/no_clutter_10/val/images\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/table_close_10/val/images\n",
            "\n",
            "Checking test image path:\n",
            "No images found in: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/TestImages/images\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'/kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/TestImages/images': False}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# prompt: check if the photos are inn the created file\n",
        "\n",
        "import glob\n",
        "\n",
        "def check_images_in_paths(paths):\n",
        "    found_images = {}\n",
        "    for path_list in paths:\n",
        "        if isinstance(path_list, str): # Handle the 'test' path which is a string\n",
        "            path_list = [path_list]\n",
        "        for path in path_list:\n",
        "            # Use glob to find all files ending with common image extensions\n",
        "            image_files = glob.glob(os.path.join(path, '*.[jJpPbBgGtT]*')) # Matches jpg, jpeg, png, bmp, gif, tiff\n",
        "            found_images[path] = len(image_files) > 0\n",
        "            if len(image_files) == 0:\n",
        "                print(f\"No images found in: {path}\")\n",
        "            else:\n",
        "                print(f\"Found {len(image_files)} images in: {path}\")\n",
        "    return found_images\n",
        "\n",
        "# Extract the paths from the data_yaml string\n",
        "import yaml\n",
        "data_config = yaml.safe_load(data_yaml)\n",
        "\n",
        "train_paths = data_config.get('train', [])\n",
        "val_paths = data_config.get('val', [])\n",
        "test_path = data_config.get('test')\n",
        "\n",
        "# Check if images exist in each of the specified paths\n",
        "print(\"Checking training image paths:\")\n",
        "check_images_in_paths(train_paths)\n",
        "\n",
        "print(\"\\nChecking validation image paths:\")\n",
        "check_images_in_paths(val_paths)\n",
        "\n",
        "print(\"\\nChecking test image path:\")\n",
        "check_images_in_paths([test_path]) # Pass test_path as a list for consistency with the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8jFvnwFU9vi",
        "outputId": "cfa32654-d082-47c0-83f9-7fb936998755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset configuration file created with updated paths\n",
            "Checking training image paths:\n",
            "Found 8 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/clutter/train/images\n",
            "Found 8 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/couch_far_10/train/images\n",
            "Found 8 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/far_10_half_clutter/train/images\n",
            "Found 8 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/film_grain_10_half_clutter/train/images\n",
            "Found 8 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/large_plant_10/train/images\n",
            "Found 8 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/no_clutter_10/train/images\n",
            "Found 8 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/table_close_10/train/images\n",
            "\n",
            "Checking validation image paths:\n",
            "Found 2 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/clutter/val/images\n",
            "Found 2 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/couch_far_10/val/images\n",
            "Found 2 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/far_10_half_clutter/val/images\n",
            "Found 2 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/film_grain_10_half_clutter/val/images\n",
            "Found 2 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/large_plant_10/val/images\n",
            "Found 2 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/no_clutter_10/val/images\n",
            "Found 2 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/table_close_10/val/images\n",
            "\n",
            "Checking test image path:\n",
            "Found 179 images in: /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/TestImages/images\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'/root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/TestImages/images': True}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# prompt: concat the root path to make it work\n",
        "multi_instance_object_detection_challenge_path = \"/root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge\"\n",
        "\n",
        "# Update the data_yaml string to use the correct root path\n",
        "data_yaml = f\"\"\"\n",
        "path: {multi_instance_object_detection_challenge_path}/Starter_Dataset\n",
        "\n",
        "train:\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/clutter/train/images\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/couch_far_10/train/images\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/far_10_half_clutter/train/images\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/film_grain_10_half_clutter/train/images\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/large_plant_10/train/images\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/no_clutter_10/train/images\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/table_close_10/train/images\n",
        "val:\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/clutter/val/images\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/couch_far_10/val/images\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/far_10_half_clutter/val/images\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/film_grain_10_half_clutter/val/images\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/large_plant_10/val/images\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/no_clutter_10/val/images\n",
        "  - {multi_instance_object_detection_challenge_path}/Starter_Dataset/table_close_10/val/images\n",
        "\n",
        "test: {multi_instance_object_detection_challenge_path}/Starter_Dataset/TestImages/images\n",
        "\n",
        "nc: 1\n",
        "names: ['soup can']\n",
        "\"\"\"\n",
        "\n",
        "# Save the updated configuration file\n",
        "with open('data.yaml', 'w') as file:\n",
        "    file.write(data_yaml)\n",
        "\n",
        "print(\"Dataset configuration file created with updated paths\")\n",
        "\n",
        "# Extract the paths from the data_yaml string again (since it was updated)\n",
        "data_config = yaml.safe_load(data_yaml)\n",
        "\n",
        "train_paths = data_config.get('train', [])\n",
        "val_paths = data_config.get('val', [])\n",
        "test_path = data_config.get('test')\n",
        "\n",
        "# Check if images exist in each of the specified paths\n",
        "print(\"Checking training image paths:\")\n",
        "check_images_in_paths(train_paths)\n",
        "\n",
        "print(\"\\nChecking validation image paths:\")\n",
        "check_images_in_paths(val_paths)\n",
        "\n",
        "print(\"\\nChecking test image path:\")\n",
        "check_images_in_paths([test_path]) # Pass test_path as a list for consistency with the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUugDN9zz2W1",
        "outputId": "12fd44b6-7af0-4871-d73e-6e05e30ed6d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21.5M/21.5M [00:00<00:00, 228MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transferred 355/355 items from pretrained weights\n",
            "Ultralytics 8.3.155 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.1, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.yaml, momentum=0.937, mosaic=0.5, multi_scale=False, name=colab_t4_yolov8s, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=yolov8s.pt, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/colab_t4_yolov8s, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0002, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
            "YOLOv8s summary: 129 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 120.3±23.9 MB/s, size: 3000.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/clutter/train/labels.cache... 56 images, 1 backgrounds, 0 corrupt: 100%|██████████| 56/56 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 120.5±25.4 MB/s, size: 3806.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/clutter/val/labels.cache... 14 images, 0 backgrounds, 0 corrupt: 100%|██████████| 14/14 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/colab_t4_yolov8s/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0002), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/colab_t4_yolov8s\u001b[0m\n",
            "Starting training for 200 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/200      3.63G     0.7032      3.054      0.945         28        640: 100%|██████████| 4/4 [00:03<00:00,  1.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.424      0.604      0.434      0.385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/200      3.63G     0.7328      3.243     0.9481         40        640: 100%|██████████| 4/4 [00:01<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.65       0.75      0.719      0.638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/200      3.66G     0.6959      1.447     0.9647         34        640: 100%|██████████| 4/4 [00:02<00:00,  1.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.745      0.821      0.714      0.639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/200      3.66G     0.7436      1.044     0.9382         26        640: 100%|██████████| 4/4 [00:01<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.709      0.821      0.717      0.617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/200      3.67G     0.6715     0.8555     0.9151         23        640: 100%|██████████| 4/4 [00:01<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.726      0.857      0.759      0.659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/200      3.67G      0.704     0.8174     0.9431         31        640: 100%|██████████| 4/4 [00:01<00:00,  3.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.769      0.821      0.804      0.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/200      3.71G     0.6653      0.735     0.8831         28        640: 100%|██████████| 4/4 [00:01<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.824       0.75      0.803      0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/200      3.71G     0.6394     0.6712     0.8666         25        640: 100%|██████████| 4/4 [00:01<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.813      0.778      0.778      0.678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/200      3.71G       0.66     0.7354      0.899         28        640: 100%|██████████| 4/4 [00:01<00:00,  3.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.842      0.763      0.828      0.725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/200      3.74G     0.7089     0.7018     0.8906         33        640: 100%|██████████| 4/4 [00:01<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.861      0.888      0.868       0.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/200      3.74G     0.6251     0.6119     0.8878         29        640: 100%|██████████| 4/4 [00:01<00:00,  3.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.747      0.821      0.825      0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/200      3.74G     0.6214      0.605     0.8682         23        640: 100%|██████████| 4/4 [00:01<00:00,  3.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.906       0.75      0.811      0.704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/200      3.78G     0.5818     0.5883     0.8576         18        640: 100%|██████████| 4/4 [00:01<00:00,  3.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.902      0.714      0.807      0.704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/200      3.78G     0.5378     0.6012     0.8553         24        640: 100%|██████████| 4/4 [00:01<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.881      0.821      0.853      0.744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/200      3.78G     0.5898     0.6493     0.8752         25        640: 100%|██████████| 4/4 [00:01<00:00,  3.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.953      0.786      0.901       0.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/200      3.81G     0.5659     0.5554      0.835         30        640: 100%|██████████| 4/4 [00:01<00:00,  2.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.803      0.871      0.897      0.806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/200      3.82G     0.5384     0.6108     0.8572         27        640: 100%|██████████| 4/4 [00:01<00:00,  3.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.755      0.714       0.74      0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/200      3.82G      0.597     0.5778     0.9124         24        640: 100%|██████████| 4/4 [00:01<00:00,  3.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.91      0.786       0.88      0.779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/200      3.82G     0.5697     0.5003     0.8431         25        640: 100%|██████████| 4/4 [00:01<00:00,  3.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.879      0.775      0.857      0.742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/200      3.85G     0.5626     0.5218     0.8645         39        640: 100%|██████████| 4/4 [00:01<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.868      0.821      0.864      0.763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/200      3.85G     0.5899     0.5272     0.8887         30        640: 100%|██████████| 4/4 [00:01<00:00,  3.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.821      0.857      0.913      0.817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/200      3.85G     0.6036     0.5298     0.8787         31        640: 100%|██████████| 4/4 [00:01<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.805      0.893      0.891      0.797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/200      3.85G     0.5782     0.4906     0.8994         31        640: 100%|██████████| 4/4 [00:01<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.903      0.893      0.936      0.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/200      3.85G     0.5582     0.5153     0.8544         21        640: 100%|██████████| 4/4 [00:00<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.912      0.857      0.934       0.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/200      3.85G     0.5892     0.4671     0.8476         36        640: 100%|██████████| 4/4 [00:01<00:00,  2.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.916      0.857      0.928      0.822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/200      3.85G     0.5326     0.4748     0.8591         20        640: 100%|██████████| 4/4 [00:01<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.939      0.857      0.925      0.824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/200      3.85G     0.5316     0.4265     0.9011         21        640: 100%|██████████| 4/4 [00:01<00:00,  3.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.877      0.857      0.892      0.789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/200      3.85G     0.5483     0.4662     0.8831         25        640: 100%|██████████| 4/4 [00:00<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.817      0.857      0.872      0.745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/200      3.85G     0.5265     0.4388     0.8612         22        640: 100%|██████████| 4/4 [00:01<00:00,  2.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.915      0.857      0.896      0.793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/200      3.85G     0.5558     0.5254     0.8958         23        640: 100%|██████████| 4/4 [00:01<00:00,  3.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.926       0.89      0.927      0.823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/200      3.85G     0.5133     0.4441     0.8747         23        640: 100%|██████████| 4/4 [00:01<00:00,  3.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.925      0.885      0.934      0.829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/200      3.85G     0.5044     0.4445     0.8692         19        640: 100%|██████████| 4/4 [00:01<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.941      0.857      0.922      0.823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/200      3.85G     0.5178     0.4266     0.8611         31        640: 100%|██████████| 4/4 [00:01<00:00,  3.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.913      0.857      0.925      0.818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/200      3.85G     0.4898     0.4303     0.8535         27        640: 100%|██████████| 4/4 [00:01<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.888      0.853      0.906      0.815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/200      3.85G     0.4715     0.4256     0.8256         22        640: 100%|██████████| 4/4 [00:01<00:00,  3.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.927      0.821      0.906      0.809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/200      3.85G     0.5303     0.4503     0.8669         37        640: 100%|██████████| 4/4 [00:01<00:00,  3.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.941      0.857      0.916      0.817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/200      3.85G     0.5014     0.4226     0.8542         17        640: 100%|██████████| 4/4 [00:01<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.914      0.857      0.915      0.806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/200      3.85G     0.5318     0.4486      0.875         29        640: 100%|██████████| 4/4 [00:01<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.888      0.847      0.895      0.789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/200      3.85G     0.5193     0.4314     0.8609         21        640: 100%|██████████| 4/4 [00:01<00:00,  3.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.825      0.844      0.859      0.766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/200      3.85G     0.4625     0.3988     0.8397         23        640: 100%|██████████| 4/4 [00:01<00:00,  3.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.825      0.845      0.863      0.769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/200      3.85G     0.5158     0.4355     0.8266         31        640: 100%|██████████| 4/4 [00:01<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.78      0.893      0.905      0.811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/200      3.89G     0.4941     0.3863     0.8471         40        640: 100%|██████████| 4/4 [00:01<00:00,  3.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.805      0.884      0.912       0.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/200      3.89G     0.4513     0.3987     0.8332         27        640: 100%|██████████| 4/4 [00:01<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.882      0.821       0.91      0.821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/200      3.89G     0.4935      0.403     0.8617         33        640: 100%|██████████| 4/4 [00:01<00:00,  3.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.904      0.821      0.908      0.822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/200      3.89G     0.4776     0.3955     0.8444         19        640: 100%|██████████| 4/4 [00:01<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.833      0.889      0.905      0.827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/200      3.89G     0.4871     0.4129     0.8657         33        640: 100%|██████████| 4/4 [00:01<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.829      0.893      0.919      0.831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/200      3.89G     0.4974     0.3905      0.865         21        640: 100%|██████████| 4/4 [00:01<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.918      0.821       0.92      0.826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/200      3.89G      0.553     0.4612     0.8684         41        640: 100%|██████████| 4/4 [00:01<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.929      0.821      0.925      0.824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/200      3.89G     0.4786     0.4127     0.8428         27        640: 100%|██████████| 4/4 [00:01<00:00,  3.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.891      0.872      0.931      0.841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/200      3.89G     0.4872     0.4219     0.8358         39        640: 100%|██████████| 4/4 [00:01<00:00,  3.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.871      0.963      0.935      0.818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/200      3.89G       0.49     0.4126     0.8383         30        640: 100%|██████████| 4/4 [00:01<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.961       0.88      0.939      0.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/200      3.89G     0.4273     0.3868     0.8281         26        640: 100%|██████████| 4/4 [00:01<00:00,  3.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.896      0.919      0.942      0.843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     53/200      3.89G     0.4609     0.3758     0.8283         26        640: 100%|██████████| 4/4 [00:01<00:00,  3.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.849      0.929      0.944      0.853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     54/200      3.89G     0.4588     0.4006     0.8285         22        640: 100%|██████████| 4/4 [00:01<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.866      0.924      0.946      0.853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     55/200      3.89G     0.4401     0.3957     0.8447         20        640: 100%|██████████| 4/4 [00:01<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.892      0.885      0.932      0.831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     56/200      3.89G     0.4413     0.3739     0.8069         30        640: 100%|██████████| 4/4 [00:01<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.921      0.893       0.91      0.832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     57/200      3.89G     0.4847     0.4106     0.8496         24        640: 100%|██████████| 4/4 [00:01<00:00,  3.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.957      0.893      0.915      0.811\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     58/200      3.89G      0.452     0.3756     0.8304         25        640: 100%|██████████| 4/4 [00:01<00:00,  3.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.926      0.892      0.905      0.804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     59/200      3.89G     0.4709     0.3904     0.8538         21        640: 100%|██████████| 4/4 [00:01<00:00,  3.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.959      0.893      0.911      0.784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     60/200      3.89G     0.4445      0.367      0.841         29        640: 100%|██████████| 4/4 [00:01<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.927      0.929      0.909      0.808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     61/200      3.93G     0.5068     0.4221     0.8356         35        640: 100%|██████████| 4/4 [00:01<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.958      0.929      0.918      0.831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     62/200      3.96G     0.4964     0.3873     0.8693         37        640: 100%|██████████| 4/4 [00:01<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.959      0.929       0.92      0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     63/200      3.96G     0.4907     0.4011     0.8363         25        640: 100%|██████████| 4/4 [00:01<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.958      0.929      0.925      0.856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     64/200      3.96G     0.4352     0.3624     0.8232         27        640: 100%|██████████| 4/4 [00:01<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.963      0.926      0.928      0.854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     65/200      3.96G     0.4356     0.3792     0.8181         28        640: 100%|██████████| 4/4 [00:01<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.928      0.923       0.92      0.844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     66/200      3.96G      0.432     0.3653     0.8362         31        640: 100%|██████████| 4/4 [00:01<00:00,  3.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.926       0.89      0.919      0.847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     67/200      3.96G     0.4558     0.3715     0.8275         38        640: 100%|██████████| 4/4 [00:01<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.926       0.89      0.913      0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     68/200      3.96G     0.4306     0.3983     0.8215         27        640: 100%|██████████| 4/4 [00:01<00:00,  3.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.959      0.845      0.912      0.835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     69/200      3.96G      0.477     0.3522     0.8454         32        640: 100%|██████████| 4/4 [00:01<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.96      0.854      0.907      0.835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     70/200      3.96G      0.421     0.3649     0.8474         26        640: 100%|██████████| 4/4 [00:01<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.96      0.857      0.907      0.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     71/200      3.96G     0.4693     0.3838     0.8267         25        640: 100%|██████████| 4/4 [00:01<00:00,  3.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.921      0.857      0.901      0.826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     72/200      3.96G     0.4479     0.3534     0.8384         19        640: 100%|██████████| 4/4 [00:01<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.958      0.808      0.902      0.845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     73/200      3.96G     0.4333     0.3803     0.8322         21        640: 100%|██████████| 4/4 [00:01<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.958      0.809      0.902      0.854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     74/200      3.96G     0.4403     0.3904     0.8316         26        640: 100%|██████████| 4/4 [00:01<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.886      0.857      0.908      0.855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     75/200      3.96G     0.4237     0.3471     0.8379         24        640: 100%|██████████| 4/4 [00:01<00:00,  3.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.921      0.857      0.909      0.854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     76/200      3.96G      0.396     0.3302     0.8162         26        640: 100%|██████████| 4/4 [00:01<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.917      0.857      0.912      0.853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     77/200      3.96G     0.4437     0.3593     0.8215         27        640: 100%|██████████| 4/4 [00:01<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.885      0.857      0.912      0.854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     78/200      3.96G     0.4176     0.3381     0.8376         23        640: 100%|██████████| 4/4 [00:01<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.957      0.805      0.916      0.854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     79/200      3.96G     0.4355      0.337     0.8336         27        640: 100%|██████████| 4/4 [00:01<00:00,  3.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.918      0.857      0.915      0.839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     80/200      3.96G      0.425     0.3324      0.835         23        640: 100%|██████████| 4/4 [00:01<00:00,  3.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.916      0.857      0.914      0.844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     81/200      3.96G     0.3951     0.3285     0.8529         26        640: 100%|██████████| 4/4 [00:01<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.914      0.857      0.911      0.858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     82/200      3.96G     0.4263     0.3745     0.8423         23        640: 100%|██████████| 4/4 [00:01<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.912      0.857       0.91      0.856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     83/200      3.96G     0.4075     0.3345     0.8186         20        640: 100%|██████████| 4/4 [00:01<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.909      0.857       0.91      0.861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     84/200      3.96G     0.4031     0.3453     0.8136         24        640: 100%|██████████| 4/4 [00:01<00:00,  2.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.959       0.83      0.915      0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     85/200      3.96G     0.4272      0.374     0.8529         21        640: 100%|██████████| 4/4 [00:01<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.96      0.847      0.917       0.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     86/200      3.96G      0.411     0.3293     0.8369         29        640: 100%|██████████| 4/4 [00:01<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.959      0.842      0.928      0.885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     87/200      3.96G     0.3953     0.3081     0.8218         22        640: 100%|██████████| 4/4 [00:01<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.98      0.821      0.928      0.874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     88/200      3.96G     0.4238     0.3323     0.8177         30        640: 100%|██████████| 4/4 [00:01<00:00,  3.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.978      0.821       0.93      0.868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     89/200      3.96G     0.4136     0.3255     0.8438         24        640: 100%|██████████| 4/4 [00:01<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.968      0.821      0.933       0.87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     90/200      3.96G     0.3871     0.3143     0.8337         22        640: 100%|██████████| 4/4 [00:01<00:00,  3.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.91      0.857      0.936      0.874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     91/200      3.96G     0.3792     0.3145     0.8235         30        640: 100%|██████████| 4/4 [00:01<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.889      0.857      0.933      0.857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     92/200      3.96G     0.3908     0.3148     0.8219         24        640: 100%|██████████| 4/4 [00:01<00:00,  3.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.897      0.857      0.925      0.869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     93/200      3.96G     0.3789     0.3141     0.8266         22        640: 100%|██████████| 4/4 [00:01<00:00,  3.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.837      0.915      0.922      0.862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     94/200      3.96G     0.4118     0.3263     0.8191         21        640: 100%|██████████| 4/4 [00:01<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.833      0.929      0.924      0.871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     95/200      3.96G     0.3833     0.3158     0.7986         18        640: 100%|██████████| 4/4 [00:01<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.87      0.857      0.934      0.856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     96/200      3.96G     0.3974      0.319     0.8181         30        640: 100%|██████████| 4/4 [00:01<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.891      0.874      0.937      0.868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     97/200      3.96G      0.389     0.3417     0.8178         27        640: 100%|██████████| 4/4 [00:01<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.858      0.866      0.938      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     98/200      3.96G     0.3733     0.3165     0.8131         30        640: 100%|██████████| 4/4 [00:01<00:00,  3.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.868      0.857      0.931      0.863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     99/200      3.96G     0.4014     0.3187     0.8119         22        640: 100%|██████████| 4/4 [00:01<00:00,  3.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.857      0.857      0.927      0.866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    100/200      3.96G     0.4033     0.3322     0.8171         35        640: 100%|██████████| 4/4 [00:01<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.809      0.929       0.93      0.865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    101/200      3.96G     0.3732     0.3214     0.7966         37        640: 100%|██████████| 4/4 [00:01<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.808      0.929      0.931      0.862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    102/200      3.96G     0.4226     0.3296     0.8327         46        640: 100%|██████████| 4/4 [00:01<00:00,  3.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.826      0.929       0.93      0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    103/200      3.96G     0.3956     0.3269     0.8496         25        640: 100%|██████████| 4/4 [00:01<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.788      0.929       0.93      0.879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    104/200      3.96G     0.3469      0.306     0.8017         18        640: 100%|██████████| 4/4 [00:01<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.81      0.929      0.931      0.871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    105/200      3.96G     0.3669     0.3184     0.8202         22        640: 100%|██████████| 4/4 [00:01<00:00,  3.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.81      0.929      0.933      0.883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    106/200      3.96G     0.3659     0.3038     0.8157         22        640: 100%|██████████| 4/4 [00:01<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.835      0.929      0.936      0.889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    107/200      3.96G     0.4225     0.3399     0.8446         29        640: 100%|██████████| 4/4 [00:01<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.835      0.929      0.935      0.882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    108/200      3.96G     0.3627     0.2997     0.8251         28        640: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.837      0.929      0.934      0.868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    109/200      3.96G     0.3778      0.315     0.8236         27        640: 100%|██████████| 4/4 [00:01<00:00,  2.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.838      0.926      0.932      0.877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    110/200      3.96G     0.3875     0.3112     0.8155         19        640: 100%|██████████| 4/4 [00:01<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.838      0.925      0.934      0.876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    111/200      3.96G     0.3741     0.3062     0.8011         24        640: 100%|██████████| 4/4 [00:01<00:00,  3.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.866       0.92      0.934      0.874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    112/200      3.96G     0.3463     0.3158     0.8243         37        640: 100%|██████████| 4/4 [00:01<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.923      0.852      0.935      0.884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    113/200      3.96G      0.389     0.3182     0.8167         24        640: 100%|██████████| 4/4 [00:01<00:00,  2.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.889      0.859      0.934      0.887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    114/200      3.96G     0.3523     0.2965     0.8084         29        640: 100%|██████████| 4/4 [00:01<00:00,  3.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.923      0.851      0.932      0.877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    115/200      3.96G     0.3476     0.2878     0.8029         31        640: 100%|██████████| 4/4 [00:01<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.922      0.841      0.932      0.866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    116/200      3.96G     0.3666     0.3093     0.7938         14        640: 100%|██████████| 4/4 [00:01<00:00,  3.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.907      0.821       0.93       0.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    117/200      3.96G     0.3808     0.3278     0.8191         21        640: 100%|██████████| 4/4 [00:01<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.896      0.821      0.928      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    118/200      3.96G     0.3447     0.2924     0.7836         17        640: 100%|██████████| 4/4 [00:01<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.852      0.823      0.927      0.865\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    119/200      3.96G     0.3673     0.2974     0.8189         23        640: 100%|██████████| 4/4 [00:01<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.86      0.875      0.925      0.858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    120/200      3.96G     0.3597     0.2968     0.8185         19        640: 100%|██████████| 4/4 [00:01<00:00,  3.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.86      0.878      0.927      0.866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    121/200      3.96G     0.3434     0.2978     0.7954         45        640: 100%|██████████| 4/4 [00:01<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.86      0.877      0.927      0.872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    122/200      3.96G      0.358     0.3055     0.8368         33        640: 100%|██████████| 4/4 [00:01<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.861      0.883       0.92      0.881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    123/200      3.96G     0.3217      0.287     0.7902         28        640: 100%|██████████| 4/4 [00:01<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.862      0.891      0.921      0.882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    124/200      3.96G     0.3387     0.3006     0.8133         32        640: 100%|██████████| 4/4 [00:01<00:00,  3.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.858      0.893      0.921      0.881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    125/200      3.96G     0.3392     0.2829     0.8241         19        640: 100%|██████████| 4/4 [00:01<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.846      0.893      0.919      0.874\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    126/200      3.96G      0.325     0.2852     0.7984         27        640: 100%|██████████| 4/4 [00:01<00:00,  3.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.841      0.893      0.916      0.865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    127/200      3.96G     0.3375     0.2824     0.8281         26        640: 100%|██████████| 4/4 [00:01<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.892      0.888      0.916      0.877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    128/200      3.96G     0.3481     0.2904     0.8178         19        640: 100%|██████████| 4/4 [00:01<00:00,  3.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.893      0.892      0.924      0.871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    129/200      3.96G     0.3232     0.2776     0.7973         28        640: 100%|██████████| 4/4 [00:01<00:00,  3.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.89      0.872      0.921      0.867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    130/200      3.96G     0.3407     0.2959     0.8024         26        640: 100%|██████████| 4/4 [00:01<00:00,  3.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.925      0.883      0.918      0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    131/200      3.96G     0.4105     0.3205     0.8484         27        640: 100%|██████████| 4/4 [00:01<00:00,  3.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.924      0.863      0.923      0.883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    132/200      3.96G     0.3223     0.2771     0.7998         19        640: 100%|██████████| 4/4 [00:01<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.961      0.878      0.929      0.883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    133/200      3.96G     0.3668     0.3004     0.8217         32        640: 100%|██████████| 4/4 [00:01<00:00,  2.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.926      0.898      0.931      0.888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    134/200      3.96G     0.3226     0.2851      0.804         16        640: 100%|██████████| 4/4 [00:01<00:00,  3.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.919      0.929      0.929      0.888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    135/200      3.96G     0.3091     0.2668     0.8148         24        640: 100%|██████████| 4/4 [00:01<00:00,  3.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.926      0.896       0.93      0.897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    136/200      3.96G     0.3342     0.3108     0.7927         25        640: 100%|██████████| 4/4 [00:01<00:00,  3.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.961      0.891      0.923      0.887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    137/200      3.96G     0.3154      0.268     0.7992         24        640: 100%|██████████| 4/4 [00:01<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.961       0.89      0.922      0.886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    138/200      3.96G      0.342     0.2998     0.8165         32        640: 100%|██████████| 4/4 [00:01<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.906      0.929      0.914      0.878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    139/200      3.96G     0.3654      0.297     0.8194         37        640: 100%|██████████| 4/4 [00:01<00:00,  3.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.916      0.929      0.915      0.876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    140/200      3.96G     0.3228     0.2712     0.7921         21        640: 100%|██████████| 4/4 [00:01<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.92      0.929      0.917      0.879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    141/200      3.96G     0.3254     0.2692     0.8055         25        640: 100%|██████████| 4/4 [00:01<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.928      0.929      0.915      0.881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    142/200      3.96G      0.315     0.2668      0.806         23        640: 100%|██████████| 4/4 [00:01<00:00,  3.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.883      0.929      0.918      0.881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    143/200      3.96G      0.322     0.2674     0.8063         29        640: 100%|██████████| 4/4 [00:01<00:00,  2.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.945      0.857      0.917      0.883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    144/200      3.96G      0.328     0.2929     0.8418         23        640: 100%|██████████| 4/4 [00:01<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.944      0.857      0.925      0.885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    145/200      3.96G     0.3443     0.2772     0.7967         34        640: 100%|██████████| 4/4 [00:01<00:00,  3.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.863      0.929      0.925      0.884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    146/200      3.96G     0.2976     0.2649     0.7898         25        640: 100%|██████████| 4/4 [00:01<00:00,  3.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.925      0.879      0.925      0.881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    147/200      3.96G     0.3044     0.2706     0.8089         24        640: 100%|██████████| 4/4 [00:01<00:00,  3.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.925      0.881      0.921      0.879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    148/200      3.96G     0.3046     0.2742     0.8171         22        640: 100%|██████████| 4/4 [00:01<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.925      0.883      0.918      0.881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    149/200      3.96G     0.3476     0.2796     0.7915         34        640: 100%|██████████| 4/4 [00:01<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.912      0.857      0.917      0.877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    150/200      3.96G     0.3478     0.2801     0.8311         32        640: 100%|██████████| 4/4 [00:01<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.909      0.857      0.916      0.877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    151/200      3.96G     0.3423     0.2903      0.811         37        640: 100%|██████████| 4/4 [00:01<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.907      0.857      0.912      0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    152/200      3.96G     0.3092      0.262     0.8048         29        640: 100%|██████████| 4/4 [00:01<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28       0.91      0.857      0.917       0.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    153/200      3.96G     0.3259     0.2689     0.8189         35        640: 100%|██████████| 4/4 [00:01<00:00,  3.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.907      0.857      0.922      0.886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    154/200      3.96G     0.3156     0.2693     0.8134         27        640: 100%|██████████| 4/4 [00:01<00:00,  3.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.913      0.857      0.933      0.895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    155/200      3.96G     0.2885      0.273     0.7974         51        640:  50%|█████     | 2/4 [00:00<00:00,  3.86it/s]"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8s.yaml\").load(\"yolov8s.pt\")  # you can also try yolov8n.yaml for even faster training\n",
        "\n",
        "results = model.train(\n",
        "    data=\"data.yaml\",\n",
        "\n",
        "    # Training performance\n",
        "    epochs=200,\n",
        "    batch=16,              # 16 fits well in 16GB for yolov8s + imgsz=640\n",
        "    imgsz=640,             # Good balance of detail and memory use\n",
        "    device=0,              # Use GPU\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer='AdamW',\n",
        "    lr0=0.001,\n",
        "    weight_decay=0.0002,\n",
        "\n",
        "    # Lighter augmentations\n",
        "    mosaic=0.5,\n",
        "    mixup=0.0,\n",
        "    copy_paste=0.0,\n",
        "    fliplr=0.5,\n",
        "    flipud=0.0,\n",
        "    erasing=0.1,\n",
        "\n",
        "    # Advanced\n",
        "    amp=True,              # Mixed precision for faster training\n",
        "\n",
        "    # Logging and saving\n",
        "    project='runs/detect',\n",
        "    name='colab_t4_yolov8s',\n",
        "    save_period=10,\n",
        "    exist_ok=True,\n",
        "    val=True\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_pvKsadYFgO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98766973-2e7f-4950-8439-bdadadff94d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.153 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 179.9±18.0 MB/s, size: 3956.7 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /root/.cache/kagglehub/competitions/multi-instance-object-detection-challenge/Starter_Dataset/clutter/val/labels.cache... 14 images, 0 backgrounds, 0 corrupt: 100%|██████████| 14/14 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         14         28      0.927      0.911      0.957      0.902\n",
            "Speed: 0.2ms preprocess, 7.9ms inference, 0.0ms loss, 24.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "mAP@50 on the validation set: 0.9566764516129032\n"
          ]
        }
      ],
      "source": [
        "# prompt: test this model and give me its mAP@50.\n",
        "\n",
        "# Validate the trained model on the validation set\n",
        "metrics = model.val()\n",
        "\n",
        "# Access the mAP@50 metric\n",
        "map50 = metrics.box.map50\n",
        "\n",
        "print(f\"mAP@50 on the validation set: {map50}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load model (assuming already trained and weights saved)\n",
        "model = YOLO(\"runs/detect/colab_t4_yolov8s/weights/best.pt\")\n",
        "\n",
        "# Get all image paths in the test set\n",
        "test_images = glob.glob(os.path.join(test_path, \"*.*\"))\n",
        "print(f\"Found {len(test_images)} test images.\")\n",
        "\n",
        "# Define chunk size (adjust to your memory; 10–20 is safe for T4 + 12GB)\n",
        "chunk_size = 20\n",
        "\n",
        "# Create a results folder\n",
        "output_dir = \"runs/detect/chunked_test\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Predict in chunks\n",
        "for i in range(0, len(test_images), chunk_size):\n",
        "    chunk = test_images[i:i + chunk_size]\n",
        "    print(f\"\\n🔄 Running inference on images {i} to {i + len(chunk) - 1}\")\n",
        "\n",
        "    model.predict(\n",
        "        source=chunk,\n",
        "        conf=0.25,\n",
        "        iou=0.45,\n",
        "        imgsz=640,\n",
        "        device=0,\n",
        "        save=True,\n",
        "        project=\"runs/detect\",\n",
        "        name=\"chunked_test\",\n",
        "        exist_ok=True\n",
        "    )\n",
        "\n",
        "print(\"\\n✅ All chunks processed! Check runs/detect/chunked_test for results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "bntuSeWCZ1UF",
        "outputId": "8d9d2b8e-6d0a-4034-cc88-665ec067fc93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ultralytics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-453218215>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load model (assuming already trained and weights saved)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: make the same predicate but on the /content/last.pt it is not testing\n",
        "\n",
        "# Load the specific model\n",
        "model = YOLO(\"/content/drive/MyDrive/saved_yolov8s_model.pt\")\n",
        "\n",
        "# Define the test path from the data_config\n",
        "test_path = data_config.get('test')\n",
        "\n",
        "# Get all image paths in the test set\n",
        "test_images = glob.glob(os.path.join(test_path, \"*.*\"))\n",
        "print(f\"Found {len(test_images)} test images for prediction with /content/last.pt.\")\n",
        "\n",
        "# Define chunk size (adjust to your memory; 10–20 is safe for T4 + 12GB)\n",
        "chunk_size = 20\n",
        "\n",
        "# Create a results folder\n",
        "output_dir = \"runs/detect/last_pt_test\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Predict in chunks\n",
        "for i in range(0, len(test_images), chunk_size):\n",
        "    chunk = test_images[i:i + chunk_size]\n",
        "    print(f\"\\n🔄 Running inference on images {i} to {i + len(chunk) - 1} using /content/last.pt\")\n",
        "\n",
        "    model.predict(\n",
        "        source=chunk,\n",
        "        conf=0.25,\n",
        "        iou=0.45,\n",
        "        imgsz=640,\n",
        "        device=0,\n",
        "        save=True,\n",
        "        project=\"runs/detect\",\n",
        "        name=\"last_pt_test\", # Unique name for this test run\n",
        "        exist_ok=True\n",
        "    )\n",
        "\n",
        "print(\"\\n✅ All chunks processed with /content/last.pt! Check runs/detect/last_pt_test for results.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "LHI2kUp1Ag1I",
        "outputId": "73658e00-518b-4241-d695-32cc91bb2f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 179 test images for prediction with /content/last.pt.\n",
            "\n",
            "🔄 Running inference on images 0 to 19 using /content/last.pt\n",
            "Ultralytics 8.3.154 🚀 Python-3.11.13 torch-2.6.0+cu124 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: None\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-156974264>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🔄 Running inference on images {i} to {i + len(chunk) - 1} using /content/last.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     model.predict(\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_cli\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# only update args if predictor is already setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_model\u001b[0;34m(self, model, verbose)\u001b[0m\n\u001b[1;32m    391\u001b[0m         self.model = AutoBackend(\n\u001b[1;32m    392\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselect_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0mdnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/utils/torch_utils.py\u001b[0m in \u001b[0;36mselect_device\u001b[0;34m(device, batch, newline, verbose)\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             )\n\u001b[0;32m--> 201\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0;34mf\"Invalid CUDA 'device={device}' requested.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;34mf\" Use 'device=cpu' or pass valid CUDA device(s) if available,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: None\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create  Submission Format\n",
        "# To participate, submit your csv file with predictions in YOLO format.\n",
        "# Each test image should have a corresponding \"image_id\" and a \"prediction_string\" with predicted bounding boxes.\n",
        "# CSV File Format\n",
        "# Each prediction should contain predictions in YOLO format:\n",
        "# \"image_id\", \"prediction string(object class class_confidence\n",
        "# x_center y_center width height)\".\n",
        "# image_id → image name without the .jpg/.png extension\n",
        "# Object class → always 0 for soup in this competition.\n",
        "# confidence → Prediction confidence (between 0 and 1).\n",
        "# x_center, y_center, width, height → Coordinates normalized between 0 and 1.\n",
        "# Example (0002.png for a single detected object)\n",
        "# \"0002\",\"0 0.9435517191886902 0.874369642469618 0.30810502370198567 0.25126071506076386 0.25204394658406576\"\n",
        "\n",
        "# Prepare submission file\n",
        "submission_df = pd.DataFrame(columns=['image_id', 'prediction_string'])\n",
        "\n",
        "# Iterate through the test images and their corresponding prediction results\n",
        "# The results are saved in the 'runs/detect/chunked_test' directory\n",
        "# Each image will have its own folder containing the results, including labels\n",
        "results_dir = \"runs/detect/chunked_test\"\n",
        "image_files = glob.glob(os.path.join(test_path, \"*.*\"))\n",
        "\n",
        "print(\"Generating submission file...\")\n",
        "\n",
        "for image_path in image_files:\n",
        "    image_id = Path(image_path).stem\n",
        "    prediction_string = \"\"\n",
        "\n",
        "    # The label files from YOLO prediction are saved in a 'labels' subdirectory within the image's result folder\n",
        "    # The structure is typically runs/detect/chunked_test/image_id/labels/image_id.txt\n",
        "    label_file = os.path.join(results_dir, image_id, \"labels\", f\"{image_id}.txt\")\n",
        "\n",
        "    if os.path.exists(label_file):\n",
        "        with open(label_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            # Each line in the label file is in the format: class confidence x_center y_center width height\n",
        "            # We need to convert this to the required submission format: 0 confidence x_center y_center width height\n",
        "            # Since the competition requires class 0 for soup, we replace the actual class (which should be 0 from training) with 0.\n",
        "            predictions = []\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5: # Ensure we have all 5 parts (class, confidence, x, y, w, h)\n",
        "                    # The label file already contains normalized coordinates\n",
        "                    # We need to add the class (which is always 0 for soup) and the confidence.\n",
        "                    # The parts are: [class, x_center, y_center, width, height] from YOLO's txt output\n",
        "                    # We need to get the confidence from the prediction result object if possible,\n",
        "                    # but the saved label files in this format don't directly include confidence.\n",
        "                    # A common approach is to re-process the model.predict results to get confidence.\n",
        "                    # However, given the constraint to use the existing code context,\n",
        "                    # and assuming the label file contains the correct format from YOLO (which *can* be configured to include confidence),\n",
        "                    # let's assume the parts are [class, x_center, y_center, width, height] and we need the confidence.\n",
        "                    # Since the prompt mentions \"class_confidence x_center y_center width height\" in the example,\n",
        "                    # let's adapt to that and assume the saved label file is actually class x_center y_center width height.\n",
        "                    # This means we need to get the confidence from the original prediction results.\n",
        "                    # Re-running prediction to get results objects is more reliable for confidence.\n",
        "\n",
        "                    # Let's adjust and re-run prediction on individual images to get the result objects\n",
        "                    # to extract confidence correctly. This is more robust.\n",
        "                    # For a large number of test images, we'd still do this in chunks.\n",
        "\n",
        "                    # To avoid re-running prediction for the entire test set here,\n",
        "                    # let's assume, for the sake of generating the submission format based on the provided label files,\n",
        "                    # that the label file *does* have the confidence. This is a limitation based on the typical YOLOv8 label file format saved after 'save=True'.\n",
        "                    # A better approach would be to process the `results` object from `model.predict` directly.\n",
        "\n",
        "                    # Let's assume the format in the label file is 'class x_c y_c w h' and we will need to insert a placeholder confidence\n",
        "                    # or, more accurately, re-run prediction to get actual confidence.\n",
        "                    # Since we *already* ran `model.predict` with `save=True`, the bounding box coordinates are saved.\n",
        "                    # The confidence is not in the saved .txt label files by default.\n",
        "                    # We *must* get the confidence from the original prediction `results` objects.\n",
        "\n",
        "                    # Let's refactor to process the prediction results directly instead of parsing saved label files.\n",
        "                    pass # We will rewrite this loop below\n",
        "\n",
        "    # Append an empty row for images with no detections (as required by some competitions)\n",
        "    # Or, based on the example, if there are no detections, the prediction_string is empty.\n",
        "    # Let's stick to the example format.\n",
        "\n",
        "# --- New approach: Process prediction results directly ---\n",
        "submission_data = []\n",
        "\n",
        "print(\"Processing prediction results for submission...\")\n",
        "\n",
        "# Re-run prediction on test images to get result objects\n",
        "# We need to do this again because the saved labels don't have confidence.\n",
        "# We'll process chunk by chunk to manage memory.\n",
        "\n",
        "test_images_paths = glob.glob(os.path.join(test_path, \"*.*\"))\n",
        "chunk_size = 20 # Use the same chunk size\n",
        "\n",
        "for i in range(0, len(test_images_paths), chunk_size):\n",
        "    chunk = test_images_paths[i:i + chunk_size]\n",
        "    print(f\"\\nProcessing chunk {int(i/chunk_size) + 1}/{(len(test_images_paths) + chunk_size - 1) // chunk_size}\")\n",
        "\n",
        "    results = model(chunk) # Run prediction on the chunk\n",
        "\n",
        "    for j, result in enumerate(results):\n",
        "        image_path = chunk[j]\n",
        "        image_id = Path(image_path).stem\n",
        "        prediction_string = \"\"\n",
        "\n",
        "        if result.boxes: # Check if any boxes were detected\n",
        "            predictions = []\n",
        "            # Iterate through detected boxes in the result object\n",
        "            for box in result.boxes:\n",
        "                confidence = box.conf.item() # Get confidence as a standard Python float\n",
        "                # Coordinates are already normalized in result.boxes\n",
        "                x_center, y_center, width, height = box.xywhn[0].tolist() # Get normalized xywh as a list\n",
        "\n",
        "                # Format: object class confidence x_center y_center width height\n",
        "                # Object class is always 0 for soup\n",
        "                prediction = f\"0 {confidence:.6f} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "                predictions.append(prediction)\n",
        "\n",
        "            prediction_string = \" \".join(predictions)\n",
        "\n",
        "        submission_data.append({'image_id': image_id, 'prediction_string': prediction_string})\n",
        "\n",
        "# Create the submission DataFrame\n",
        "submission_df = pd.DataFrame(submission_data)\n",
        "\n",
        "# Save the submission file\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"\\nSubmission file 'submission.csv' created successfully.\")\n",
        "print(submission_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2Y-ew8XfivL",
        "outputId": "1ee62a0d-fdbf-48f7-c5c1-c0419ee0c849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating submission file...\n",
            "Processing prediction results for submission...\n",
            "\n",
            "Processing chunk 1/9\n",
            "\n",
            "0: 640x640 2 soup cans, 11.7ms\n",
            "1: 640x640 2 soup cans, 11.7ms\n",
            "2: 640x640 3 soup cans, 11.7ms\n",
            "3: 640x640 2 soup cans, 11.7ms\n",
            "4: 640x640 1 soup can, 11.7ms\n",
            "5: 640x640 3 soup cans, 11.7ms\n",
            "6: 640x640 2 soup cans, 11.7ms\n",
            "7: 640x640 3 soup cans, 11.7ms\n",
            "8: 640x640 3 soup cans, 11.7ms\n",
            "9: 640x640 7 soup cans, 11.7ms\n",
            "10: 640x640 3 soup cans, 11.7ms\n",
            "11: 640x640 2 soup cans, 11.7ms\n",
            "12: 640x640 2 soup cans, 11.7ms\n",
            "13: 640x640 6 soup cans, 11.7ms\n",
            "14: 640x640 3 soup cans, 11.7ms\n",
            "15: 640x640 2 soup cans, 11.7ms\n",
            "16: 640x640 1 soup can, 11.7ms\n",
            "17: 640x640 2 soup cans, 11.7ms\n",
            "18: 640x640 3 soup cans, 11.7ms\n",
            "19: 640x640 12 soup cans, 11.7ms\n",
            "Speed: 5.1ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 2/9\n",
            "\n",
            "0: 640x640 3 soup cans, 10.4ms\n",
            "1: 640x640 2 soup cans, 10.4ms\n",
            "2: 640x640 2 soup cans, 10.4ms\n",
            "3: 640x640 2 soup cans, 10.4ms\n",
            "4: 640x640 4 soup cans, 10.4ms\n",
            "5: 640x640 2 soup cans, 10.4ms\n",
            "6: 640x640 9 soup cans, 10.4ms\n",
            "7: 640x640 5 soup cans, 10.4ms\n",
            "8: 640x640 4 soup cans, 10.4ms\n",
            "9: 640x640 4 soup cans, 10.4ms\n",
            "10: 640x640 4 soup cans, 10.4ms\n",
            "11: 640x640 2 soup cans, 10.4ms\n",
            "12: 640x640 3 soup cans, 10.4ms\n",
            "13: 640x640 2 soup cans, 10.4ms\n",
            "14: 640x640 1 soup can, 10.4ms\n",
            "15: 640x640 3 soup cans, 10.4ms\n",
            "16: 640x640 (no detections), 10.4ms\n",
            "17: 640x640 2 soup cans, 10.4ms\n",
            "18: 640x640 6 soup cans, 10.4ms\n",
            "19: 640x640 2 soup cans, 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 3/9\n",
            "\n",
            "0: 640x640 2 soup cans, 11.0ms\n",
            "1: 640x640 3 soup cans, 11.0ms\n",
            "2: 640x640 5 soup cans, 11.0ms\n",
            "3: 640x640 2 soup cans, 11.0ms\n",
            "4: 640x640 2 soup cans, 11.0ms\n",
            "5: 640x640 2 soup cans, 11.0ms\n",
            "6: 640x640 2 soup cans, 11.0ms\n",
            "7: 640x640 2 soup cans, 11.0ms\n",
            "8: 640x640 3 soup cans, 11.0ms\n",
            "9: 640x640 3 soup cans, 11.0ms\n",
            "10: 640x640 3 soup cans, 11.0ms\n",
            "11: 640x640 3 soup cans, 11.0ms\n",
            "12: 640x640 4 soup cans, 11.0ms\n",
            "13: 640x640 3 soup cans, 11.0ms\n",
            "14: 640x640 2 soup cans, 11.0ms\n",
            "15: 640x640 4 soup cans, 11.0ms\n",
            "16: 640x640 7 soup cans, 11.0ms\n",
            "17: 640x640 3 soup cans, 11.0ms\n",
            "18: 640x640 5 soup cans, 11.0ms\n",
            "19: 640x640 2 soup cans, 11.0ms\n",
            "Speed: 3.7ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 4/9\n",
            "\n",
            "0: 480x640 2 soup cans, 8.7ms\n",
            "1: 480x640 1 soup can, 8.7ms\n",
            "2: 480x640 1 soup can, 8.7ms\n",
            "3: 480x640 7 soup cans, 8.7ms\n",
            "4: 480x640 3 soup cans, 8.7ms\n",
            "5: 480x640 3 soup cans, 8.7ms\n",
            "6: 480x640 3 soup cans, 8.7ms\n",
            "7: 480x640 1 soup can, 8.7ms\n",
            "8: 480x640 7 soup cans, 8.7ms\n",
            "9: 480x640 2 soup cans, 8.7ms\n",
            "10: 480x640 3 soup cans, 8.7ms\n",
            "11: 480x640 1 soup can, 8.7ms\n",
            "12: 480x640 4 soup cans, 8.7ms\n",
            "13: 480x640 11 soup cans, 8.7ms\n",
            "14: 480x640 1 soup can, 8.7ms\n",
            "15: 480x640 1 soup can, 8.7ms\n",
            "16: 480x640 (no detections), 8.7ms\n",
            "17: 480x640 6 soup cans, 8.7ms\n",
            "18: 480x640 4 soup cans, 8.7ms\n",
            "19: 480x640 3 soup cans, 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "Processing chunk 5/9\n",
            "\n",
            "0: 640x640 2 soup cans, 10.6ms\n",
            "1: 640x640 1 soup can, 10.6ms\n",
            "2: 640x640 5 soup cans, 10.6ms\n",
            "3: 640x640 2 soup cans, 10.6ms\n",
            "4: 640x640 7 soup cans, 10.6ms\n",
            "5: 640x640 1 soup can, 10.6ms\n",
            "6: 640x640 2 soup cans, 10.6ms\n",
            "7: 640x640 4 soup cans, 10.6ms\n",
            "8: 640x640 3 soup cans, 10.6ms\n",
            "9: 640x640 3 soup cans, 10.6ms\n",
            "10: 640x640 4 soup cans, 10.6ms\n",
            "11: 640x640 2 soup cans, 10.6ms\n",
            "12: 640x640 3 soup cans, 10.6ms\n",
            "13: 640x640 7 soup cans, 10.6ms\n",
            "14: 640x640 3 soup cans, 10.6ms\n",
            "15: 640x640 2 soup cans, 10.6ms\n",
            "16: 640x640 1 soup can, 10.6ms\n",
            "17: 640x640 11 soup cans, 10.6ms\n",
            "18: 640x640 3 soup cans, 10.6ms\n",
            "19: 640x640 2 soup cans, 10.6ms\n",
            "Speed: 3.7ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 6/9\n",
            "\n",
            "0: 640x640 2 soup cans, 11.0ms\n",
            "1: 640x640 1 soup can, 11.0ms\n",
            "2: 640x640 3 soup cans, 11.0ms\n",
            "3: 640x640 2 soup cans, 11.0ms\n",
            "4: 640x640 1 soup can, 11.0ms\n",
            "5: 640x640 2 soup cans, 11.0ms\n",
            "6: 640x640 3 soup cans, 11.0ms\n",
            "7: 640x640 4 soup cans, 11.0ms\n",
            "8: 640x640 3 soup cans, 11.0ms\n",
            "9: 640x640 1 soup can, 11.0ms\n",
            "10: 640x640 3 soup cans, 11.0ms\n",
            "11: 640x640 2 soup cans, 11.0ms\n",
            "12: 640x640 3 soup cans, 11.0ms\n",
            "13: 640x640 1 soup can, 11.0ms\n",
            "14: 640x640 4 soup cans, 11.0ms\n",
            "15: 640x640 2 soup cans, 11.0ms\n",
            "16: 640x640 3 soup cans, 11.0ms\n",
            "17: 640x640 2 soup cans, 11.0ms\n",
            "18: 640x640 2 soup cans, 11.0ms\n",
            "19: 640x640 1 soup can, 11.0ms\n",
            "Speed: 4.9ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 7/9\n",
            "\n",
            "0: 640x640 1 soup can, 10.6ms\n",
            "1: 640x640 4 soup cans, 10.6ms\n",
            "2: 640x640 2 soup cans, 10.6ms\n",
            "3: 640x640 1 soup can, 10.6ms\n",
            "4: 640x640 5 soup cans, 10.6ms\n",
            "5: 640x640 1 soup can, 10.6ms\n",
            "6: 640x640 2 soup cans, 10.6ms\n",
            "7: 640x640 4 soup cans, 10.6ms\n",
            "8: 640x640 2 soup cans, 10.6ms\n",
            "9: 640x640 1 soup can, 10.6ms\n",
            "10: 640x640 3 soup cans, 10.6ms\n",
            "11: 640x640 3 soup cans, 10.6ms\n",
            "12: 640x640 4 soup cans, 10.6ms\n",
            "13: 640x640 2 soup cans, 10.6ms\n",
            "14: 640x640 3 soup cans, 10.6ms\n",
            "15: 640x640 2 soup cans, 10.6ms\n",
            "16: 640x640 2 soup cans, 10.6ms\n",
            "17: 640x640 2 soup cans, 10.6ms\n",
            "18: 640x640 2 soup cans, 10.6ms\n",
            "19: 640x640 2 soup cans, 10.6ms\n",
            "Speed: 3.7ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 8/9\n",
            "\n",
            "0: 640x640 3 soup cans, 10.5ms\n",
            "1: 640x640 2 soup cans, 10.5ms\n",
            "2: 640x640 3 soup cans, 10.5ms\n",
            "3: 640x640 2 soup cans, 10.5ms\n",
            "4: 640x640 4 soup cans, 10.5ms\n",
            "5: 640x640 3 soup cans, 10.5ms\n",
            "6: 640x640 1 soup can, 10.5ms\n",
            "7: 640x640 2 soup cans, 10.5ms\n",
            "8: 640x640 4 soup cans, 10.5ms\n",
            "9: 640x640 6 soup cans, 10.5ms\n",
            "10: 640x640 4 soup cans, 10.5ms\n",
            "11: 640x640 1 soup can, 10.5ms\n",
            "12: 640x640 1 soup can, 10.5ms\n",
            "13: 640x640 2 soup cans, 10.5ms\n",
            "14: 640x640 3 soup cans, 10.5ms\n",
            "15: 640x640 2 soup cans, 10.5ms\n",
            "16: 640x640 4 soup cans, 10.5ms\n",
            "17: 640x640 7 soup cans, 10.5ms\n",
            "18: 640x640 2 soup cans, 10.5ms\n",
            "19: 640x640 2 soup cans, 10.5ms\n",
            "Speed: 3.5ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 9/9\n",
            "\n",
            "0: 640x640 2 soup cans, 11.9ms\n",
            "1: 640x640 2 soup cans, 11.9ms\n",
            "2: 640x640 6 soup cans, 11.9ms\n",
            "3: 640x640 3 soup cans, 11.9ms\n",
            "4: 640x640 3 soup cans, 11.9ms\n",
            "5: 640x640 1 soup can, 11.9ms\n",
            "6: 640x640 4 soup cans, 11.9ms\n",
            "7: 640x640 4 soup cans, 11.9ms\n",
            "8: 640x640 2 soup cans, 11.9ms\n",
            "9: 640x640 2 soup cans, 11.9ms\n",
            "10: 640x640 3 soup cans, 11.9ms\n",
            "11: 640x640 2 soup cans, 11.9ms\n",
            "12: 640x640 2 soup cans, 11.9ms\n",
            "13: 640x640 2 soup cans, 11.9ms\n",
            "14: 640x640 3 soup cans, 11.9ms\n",
            "15: 640x640 2 soup cans, 11.9ms\n",
            "16: 640x640 1 soup can, 11.9ms\n",
            "17: 640x640 3 soup cans, 11.9ms\n",
            "18: 640x640 3 soup cans, 11.9ms\n",
            "Speed: 3.7ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Submission file 'submission.csv' created successfully.\n",
            "   image_id                                  prediction_string\n",
            "0  IMG_9757  0 0.897171 0.577790 0.301068 0.054396 0.103128...\n",
            "1  IMG_9792  0 0.929153 0.583613 0.751287 0.079941 0.145574...\n",
            "2  IMG_9607  0 0.949492 0.690762 0.471921 0.175357 0.169644...\n",
            "3  IMG_9567  0 0.949058 0.763976 0.492270 0.137844 0.136842...\n",
            "4  IMG_9769     0 0.830970 0.294869 0.577469 0.270854 0.676866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: make sure it does not contain null values\n",
        "\n",
        "# Check for null values in the submission DataFrame\n",
        "print(\"\\nChecking for null values in the submission DataFrame:\")\n",
        "print(submission_df.isnull().sum())\n",
        "\n",
        "# If there are nulls, you might need to investigate where they are coming from\n",
        "# and decide how to handle them (e.g., fill with empty string if 'prediction_string' is null)\n",
        "# In this specific case, based on the logic, 'prediction_string' should be an empty string if no detections\n",
        "# or a non-empty string if detections exist. 'image_id' should never be null.\n",
        "# However, let's add a check and fill if necessary.\n",
        "if submission_df['prediction_string'].isnull().any():\n",
        "  print(\"\\nFound null values in 'prediction_string'. Filling with empty string.\")\n",
        "  submission_df['prediction_string'] = submission_df['prediction_string'].fillna('')\n",
        "\n",
        "# Re-save the submission file after handling potential nulls\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"\\nSubmission file 'submission.csv' saved after null check.\")\n",
        "print(submission_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_FavRgOgtry",
        "outputId": "be355ac7-db9f-4770-ff27-e6359503b5a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking for null values in the submission DataFrame:\n",
            "image_id             0\n",
            "prediction_string    0\n",
            "dtype: int64\n",
            "\n",
            "Submission file 'submission.csv' saved after null check.\n",
            "   image_id                                  prediction_string\n",
            "0  IMG_9757  0 0.897171 0.577790 0.301068 0.054396 0.103128...\n",
            "1  IMG_9792  0 0.929153 0.583613 0.751287 0.079941 0.145574...\n",
            "2  IMG_9607  0 0.949492 0.690762 0.471921 0.175357 0.169644...\n",
            "3  IMG_9567  0 0.949058 0.763976 0.492270 0.137844 0.136842...\n",
            "4  IMG_9769     0 0.830970 0.294869 0.577469 0.270854 0.676866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: download this file on my machine\n",
        "\n",
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6Mplnm77gHD8",
        "outputId": "34c58409-62b2-4507-d5f7-9d42858c735f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7116877c-2116-443c-af72-d1748a763a8f\", \"submission.csv\", 26127)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from pathlib import Path\n",
        "import csv\n",
        "from ultralytics import YOLO\n",
        "import glob # Added import for glob\n",
        "\n",
        "def create_submission_from_results(\n",
        "    model_path,\n",
        "    test_images_folder,\n",
        "    output_csv=\"submission.csv\",\n",
        "    confidence_threshold=0.25, # Use the same confidence as prediction\n",
        "    allowed_extensions=(\".jpg\", \".png\", \".jpeg\")\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate the submission CSV file from YOLO prediction results.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): Path to the trained YOLO model weights (e.g., 'best.pt').\n",
        "        test_images_folder (str): Path to the folder containing test images.\n",
        "        output_csv (str): Path to save the output submission CSV file.\n",
        "        confidence_threshold (float): Minimum confidence score to include a prediction.\n",
        "        allowed_extensions (tuple): Tuple of allowed image file extensions.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The submission DataFrame.\n",
        "    \"\"\"\n",
        "    model = YOLO(model_path)\n",
        "    test_images_path = Path(test_images_folder)\n",
        "\n",
        "    # Get all image paths in the test set\n",
        "    test_image_files = [str(p) for p in test_images_path.glob(\"*\") if p.suffix.lower() in allowed_extensions]\n",
        "    print(f\"Found {len(test_image_files)} test images.\")\n",
        "\n",
        "    submission_data = []\n",
        "    chunk_size = 20 # Use a reasonable chunk size for prediction\n",
        "\n",
        "    print(\"Processing prediction results for submission...\")\n",
        "\n",
        "    # Process prediction results in chunks\n",
        "    for i in range(0, len(test_image_files), chunk_size):\n",
        "        chunk = test_image_files[i:i + chunk_size]\n",
        "        print(f\"\\nProcessing chunk {int(i/chunk_size) + 1}/{(len(test_image_files) + chunk_size - 1) // chunk_size}\")\n",
        "\n",
        "        results = model(chunk) # Run prediction on the chunk\n",
        "\n",
        "        for j, result in enumerate(results):\n",
        "            image_path = chunk[j]\n",
        "            image_id = Path(image_path).stem\n",
        "            prediction_string = \"\"\n",
        "\n",
        "            if result.boxes: # Check if any boxes were detected\n",
        "                predictions = []\n",
        "                # Iterate through detected boxes in the result object\n",
        "                for box in result.boxes:\n",
        "                    confidence = box.conf.item() # Get confidence as a standard Python float\n",
        "\n",
        "                    # Apply confidence threshold\n",
        "                    if confidence >= confidence_threshold:\n",
        "                        # Coordinates are already normalized in result.boxes\n",
        "                        x_center, y_center, width, height = box.xywhn[0].tolist() # Get normalized xywh as a list\n",
        "\n",
        "                        # Format: object class confidence x_center y_center width height\n",
        "                        # Object class is always 0 for soup in this competition\n",
        "                        prediction = f\"0 {confidence:.6f} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "                        predictions.append(prediction)\n",
        "\n",
        "                prediction_string = \" \".join(predictions)\n",
        "\n",
        "            submission_data.append({'image_id': image_id, 'prediction_string': prediction_string})\n",
        "\n",
        "    # Create the submission DataFrame\n",
        "    submission_df = pd.DataFrame(submission_data)\n",
        "\n",
        "    # Sort by image_id\n",
        "    submission_df = submission_df.sort_values('image_id')\n",
        "\n",
        "    # Save the submission file\n",
        "    submission_df.to_csv(output_csv, index=False)\n",
        "\n",
        "    print(f\"\\nSubmission file '{output_csv}' created successfully.\")\n",
        "    print(\"Submission Preview:\")\n",
        "    print(submission_df.head())\n",
        "    print(f\"Submission file shape: {submission_df.shape}\")\n",
        "\n",
        "    return submission_df\n",
        "\n",
        "# --- How to use the function ---\n",
        "# Assuming your best model weights are saved at 'runs/detect/colab_t4_yolov8s/weights/best.pt'\n",
        "# and your test images are at the path defined in data_yaml['test']\n",
        "# You might need to adjust the paths based on your actual setup.\n",
        "\n",
        "# First, make sure you have the 'test_path' variable defined from your data_yaml\n",
        "import yaml\n",
        "data_config = yaml.safe_load(data_yaml)\n",
        "test_path = data_config.get('test')\n",
        "\n",
        "# Call the function to create the submission file\n",
        "submission_df = create_submission_from_results(\n",
        "    model_path='runs/detect/colab_t4_yolov8s/weights/best.pt', # Adjust if your model path is different\n",
        "    test_images_folder=test_path,\n",
        "    output_csv='submission_from_results.csv' # Name your output file\n",
        ")\n",
        "\n",
        "# Optional: Check for null values again if needed\n",
        "print(\"\\nChecking for null values in the generated submission DataFrame:\")\n",
        "print(submission_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f00_5M6iKsj",
        "outputId": "f93f5b65-7606-42f2-a112-c740356a73a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 179 test images.\n",
            "Processing prediction results for submission...\n",
            "\n",
            "Processing chunk 1/9\n",
            "\n",
            "0: 640x640 2 soup cans, 11.5ms\n",
            "1: 640x640 2 soup cans, 11.5ms\n",
            "2: 640x640 3 soup cans, 11.5ms\n",
            "3: 640x640 2 soup cans, 11.5ms\n",
            "4: 640x640 1 soup can, 11.5ms\n",
            "5: 640x640 3 soup cans, 11.5ms\n",
            "6: 640x640 2 soup cans, 11.5ms\n",
            "7: 640x640 3 soup cans, 11.5ms\n",
            "8: 640x640 3 soup cans, 11.5ms\n",
            "9: 640x640 7 soup cans, 11.5ms\n",
            "10: 640x640 3 soup cans, 11.5ms\n",
            "11: 640x640 2 soup cans, 11.5ms\n",
            "12: 640x640 2 soup cans, 11.5ms\n",
            "13: 640x640 6 soup cans, 11.5ms\n",
            "14: 640x640 3 soup cans, 11.5ms\n",
            "15: 640x640 2 soup cans, 11.5ms\n",
            "16: 640x640 1 soup can, 11.5ms\n",
            "17: 640x640 2 soup cans, 11.5ms\n",
            "18: 640x640 3 soup cans, 11.5ms\n",
            "19: 640x640 12 soup cans, 11.5ms\n",
            "Speed: 4.8ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 2/9\n",
            "\n",
            "0: 640x640 3 soup cans, 11.2ms\n",
            "1: 640x640 2 soup cans, 11.2ms\n",
            "2: 640x640 2 soup cans, 11.2ms\n",
            "3: 640x640 2 soup cans, 11.2ms\n",
            "4: 640x640 4 soup cans, 11.2ms\n",
            "5: 640x640 2 soup cans, 11.2ms\n",
            "6: 640x640 9 soup cans, 11.2ms\n",
            "7: 640x640 5 soup cans, 11.2ms\n",
            "8: 640x640 4 soup cans, 11.2ms\n",
            "9: 640x640 4 soup cans, 11.2ms\n",
            "10: 640x640 4 soup cans, 11.2ms\n",
            "11: 640x640 2 soup cans, 11.2ms\n",
            "12: 640x640 3 soup cans, 11.2ms\n",
            "13: 640x640 2 soup cans, 11.2ms\n",
            "14: 640x640 1 soup can, 11.2ms\n",
            "15: 640x640 3 soup cans, 11.2ms\n",
            "16: 640x640 (no detections), 11.2ms\n",
            "17: 640x640 2 soup cans, 11.2ms\n",
            "18: 640x640 6 soup cans, 11.2ms\n",
            "19: 640x640 2 soup cans, 11.2ms\n",
            "Speed: 3.7ms preprocess, 11.2ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 3/9\n",
            "\n",
            "0: 640x640 2 soup cans, 11.1ms\n",
            "1: 640x640 3 soup cans, 11.1ms\n",
            "2: 640x640 5 soup cans, 11.1ms\n",
            "3: 640x640 2 soup cans, 11.1ms\n",
            "4: 640x640 2 soup cans, 11.1ms\n",
            "5: 640x640 2 soup cans, 11.1ms\n",
            "6: 640x640 2 soup cans, 11.1ms\n",
            "7: 640x640 2 soup cans, 11.1ms\n",
            "8: 640x640 3 soup cans, 11.1ms\n",
            "9: 640x640 3 soup cans, 11.1ms\n",
            "10: 640x640 3 soup cans, 11.1ms\n",
            "11: 640x640 3 soup cans, 11.1ms\n",
            "12: 640x640 4 soup cans, 11.1ms\n",
            "13: 640x640 3 soup cans, 11.1ms\n",
            "14: 640x640 2 soup cans, 11.1ms\n",
            "15: 640x640 4 soup cans, 11.1ms\n",
            "16: 640x640 7 soup cans, 11.1ms\n",
            "17: 640x640 3 soup cans, 11.1ms\n",
            "18: 640x640 5 soup cans, 11.1ms\n",
            "19: 640x640 2 soup cans, 11.1ms\n",
            "Speed: 3.7ms preprocess, 11.1ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 4/9\n",
            "\n",
            "0: 480x640 2 soup cans, 8.2ms\n",
            "1: 480x640 1 soup can, 8.2ms\n",
            "2: 480x640 1 soup can, 8.2ms\n",
            "3: 480x640 7 soup cans, 8.2ms\n",
            "4: 480x640 3 soup cans, 8.2ms\n",
            "5: 480x640 3 soup cans, 8.2ms\n",
            "6: 480x640 3 soup cans, 8.2ms\n",
            "7: 480x640 1 soup can, 8.2ms\n",
            "8: 480x640 7 soup cans, 8.2ms\n",
            "9: 480x640 2 soup cans, 8.2ms\n",
            "10: 480x640 3 soup cans, 8.2ms\n",
            "11: 480x640 1 soup can, 8.2ms\n",
            "12: 480x640 4 soup cans, 8.2ms\n",
            "13: 480x640 11 soup cans, 8.2ms\n",
            "14: 480x640 1 soup can, 8.2ms\n",
            "15: 480x640 1 soup can, 8.2ms\n",
            "16: 480x640 (no detections), 8.2ms\n",
            "17: 480x640 6 soup cans, 8.2ms\n",
            "18: 480x640 4 soup cans, 8.2ms\n",
            "19: 480x640 3 soup cans, 8.2ms\n",
            "Speed: 4.3ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "Processing chunk 5/9\n",
            "\n",
            "0: 640x640 2 soup cans, 11.4ms\n",
            "1: 640x640 1 soup can, 11.4ms\n",
            "2: 640x640 5 soup cans, 11.4ms\n",
            "3: 640x640 2 soup cans, 11.4ms\n",
            "4: 640x640 7 soup cans, 11.4ms\n",
            "5: 640x640 1 soup can, 11.4ms\n",
            "6: 640x640 2 soup cans, 11.4ms\n",
            "7: 640x640 4 soup cans, 11.4ms\n",
            "8: 640x640 3 soup cans, 11.4ms\n",
            "9: 640x640 3 soup cans, 11.4ms\n",
            "10: 640x640 4 soup cans, 11.4ms\n",
            "11: 640x640 2 soup cans, 11.4ms\n",
            "12: 640x640 3 soup cans, 11.4ms\n",
            "13: 640x640 7 soup cans, 11.4ms\n",
            "14: 640x640 3 soup cans, 11.4ms\n",
            "15: 640x640 2 soup cans, 11.4ms\n",
            "16: 640x640 1 soup can, 11.4ms\n",
            "17: 640x640 11 soup cans, 11.4ms\n",
            "18: 640x640 3 soup cans, 11.4ms\n",
            "19: 640x640 2 soup cans, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 6/9\n",
            "\n",
            "0: 640x640 2 soup cans, 11.5ms\n",
            "1: 640x640 1 soup can, 11.5ms\n",
            "2: 640x640 3 soup cans, 11.5ms\n",
            "3: 640x640 2 soup cans, 11.5ms\n",
            "4: 640x640 1 soup can, 11.5ms\n",
            "5: 640x640 2 soup cans, 11.5ms\n",
            "6: 640x640 3 soup cans, 11.5ms\n",
            "7: 640x640 4 soup cans, 11.5ms\n",
            "8: 640x640 3 soup cans, 11.5ms\n",
            "9: 640x640 1 soup can, 11.5ms\n",
            "10: 640x640 3 soup cans, 11.5ms\n",
            "11: 640x640 2 soup cans, 11.5ms\n",
            "12: 640x640 3 soup cans, 11.5ms\n",
            "13: 640x640 1 soup can, 11.5ms\n",
            "14: 640x640 4 soup cans, 11.5ms\n",
            "15: 640x640 2 soup cans, 11.5ms\n",
            "16: 640x640 3 soup cans, 11.5ms\n",
            "17: 640x640 2 soup cans, 11.5ms\n",
            "18: 640x640 2 soup cans, 11.5ms\n",
            "19: 640x640 1 soup can, 11.5ms\n",
            "Speed: 3.5ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 7/9\n",
            "\n",
            "0: 640x640 1 soup can, 11.6ms\n",
            "1: 640x640 4 soup cans, 11.6ms\n",
            "2: 640x640 2 soup cans, 11.6ms\n",
            "3: 640x640 1 soup can, 11.6ms\n",
            "4: 640x640 5 soup cans, 11.6ms\n",
            "5: 640x640 1 soup can, 11.6ms\n",
            "6: 640x640 2 soup cans, 11.6ms\n",
            "7: 640x640 4 soup cans, 11.6ms\n",
            "8: 640x640 2 soup cans, 11.6ms\n",
            "9: 640x640 1 soup can, 11.6ms\n",
            "10: 640x640 3 soup cans, 11.6ms\n",
            "11: 640x640 3 soup cans, 11.6ms\n",
            "12: 640x640 4 soup cans, 11.6ms\n",
            "13: 640x640 2 soup cans, 11.6ms\n",
            "14: 640x640 3 soup cans, 11.6ms\n",
            "15: 640x640 2 soup cans, 11.6ms\n",
            "16: 640x640 2 soup cans, 11.6ms\n",
            "17: 640x640 2 soup cans, 11.6ms\n",
            "18: 640x640 2 soup cans, 11.6ms\n",
            "19: 640x640 2 soup cans, 11.6ms\n",
            "Speed: 3.6ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 8/9\n",
            "\n",
            "0: 640x640 3 soup cans, 10.6ms\n",
            "1: 640x640 2 soup cans, 10.6ms\n",
            "2: 640x640 3 soup cans, 10.6ms\n",
            "3: 640x640 2 soup cans, 10.6ms\n",
            "4: 640x640 4 soup cans, 10.6ms\n",
            "5: 640x640 3 soup cans, 10.6ms\n",
            "6: 640x640 1 soup can, 10.6ms\n",
            "7: 640x640 2 soup cans, 10.6ms\n",
            "8: 640x640 4 soup cans, 10.6ms\n",
            "9: 640x640 6 soup cans, 10.6ms\n",
            "10: 640x640 4 soup cans, 10.6ms\n",
            "11: 640x640 1 soup can, 10.6ms\n",
            "12: 640x640 1 soup can, 10.6ms\n",
            "13: 640x640 2 soup cans, 10.6ms\n",
            "14: 640x640 3 soup cans, 10.6ms\n",
            "15: 640x640 2 soup cans, 10.6ms\n",
            "16: 640x640 4 soup cans, 10.6ms\n",
            "17: 640x640 7 soup cans, 10.6ms\n",
            "18: 640x640 2 soup cans, 10.6ms\n",
            "19: 640x640 2 soup cans, 10.6ms\n",
            "Speed: 3.6ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Processing chunk 9/9\n",
            "\n",
            "0: 640x640 2 soup cans, 11.3ms\n",
            "1: 640x640 2 soup cans, 11.3ms\n",
            "2: 640x640 6 soup cans, 11.3ms\n",
            "3: 640x640 3 soup cans, 11.3ms\n",
            "4: 640x640 3 soup cans, 11.3ms\n",
            "5: 640x640 1 soup can, 11.3ms\n",
            "6: 640x640 4 soup cans, 11.3ms\n",
            "7: 640x640 4 soup cans, 11.3ms\n",
            "8: 640x640 2 soup cans, 11.3ms\n",
            "9: 640x640 2 soup cans, 11.3ms\n",
            "10: 640x640 3 soup cans, 11.3ms\n",
            "11: 640x640 2 soup cans, 11.3ms\n",
            "12: 640x640 2 soup cans, 11.3ms\n",
            "13: 640x640 2 soup cans, 11.3ms\n",
            "14: 640x640 3 soup cans, 11.3ms\n",
            "15: 640x640 2 soup cans, 11.3ms\n",
            "16: 640x640 1 soup can, 11.3ms\n",
            "17: 640x640 3 soup cans, 11.3ms\n",
            "18: 640x640 3 soup cans, 11.3ms\n",
            "Speed: 4.8ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Submission file 'submission_from_results.csv' created successfully.\n",
            "Submission Preview:\n",
            "     image_id                                  prediction_string\n",
            "164  IMG_9562  0 0.941095 0.282437 0.276353 0.077895 0.148537...\n",
            "64   IMG_9563  0 0.880785 0.525480 0.579491 0.326818 0.345432...\n",
            "33   IMG_9564  0 0.909203 0.481050 0.462901 0.228213 0.299315...\n",
            "168  IMG_9565  0 0.853321 0.697713 0.189408 0.126730 0.127765...\n",
            "10   IMG_9566  0 0.970180 0.358000 0.628993 0.126587 0.223958...\n",
            "Submission file shape: (179, 2)\n",
            "\n",
            "Checking for null values in the generated submission DataFrame:\n",
            "image_id             0\n",
            "prediction_string    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: download the submission from results file\n",
        "\n",
        "files.download('submission_from_results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Z8i5tz5Ljy8T",
        "outputId": "60c66957-0b5c-461c-c423-3b2199054fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5265204c-6ddc-478d-bcca-d6f17a4be80a\", \"submission_from_results.csv\", 26127)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4tGrbh6TLZa",
        "outputId": "cc62ff24-c29c-4b48-b16a-86fa6aba5d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/saved_yolov8s_model.pt\""
      ],
      "metadata": {
        "id": "RCErQMqZTmnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "saved_model = YOLO(model_path)\n"
      ],
      "metadata": {
        "id": "z9HJYEcBTxb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_path = \"/kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/TestImages/images\"\n"
      ],
      "metadata": {
        "id": "dIMTtdSMVFUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📝 Step 6: Optimized Label Generation\n",
        "# ===============================================\n",
        "\n",
        "print(\"📝 Generating optimized prediction labels...\")\n",
        "\n",
        "# Create output directory\n",
        "output_dir = \"/content/submission\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# 🎯 Optimization parameters for multi-instance detection\n",
        "conf_threshold = 0.25            # Lower confidence threshold\n",
        "iou_threshold = 0.45             # Non-Max Suppression (NMS) threshold\n",
        "max_detections_per_image = 3     # Max number of detections per image\n",
        "\n",
        "# Process all test images\n",
        "for img_path in Path(test_data_path).glob(\"*\"):\n",
        "    if img_path.suffix.lower() not in ['.jpg', '.jpeg', '.png']:\n",
        "        continue\n",
        "\n",
        "    # 🔥 Run prediction using optimized parameters\n",
        "    results = saved_model.predict(\n",
        "        img_path,\n",
        "        conf=conf_threshold,\n",
        "        iou=iou_threshold,\n",
        "        agnostic_nms=True,\n",
        "        max_det=max_detections_per_image,\n",
        "        augment=True,           # Enable test-time augmentation\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    # Output label file\n",
        "    output_txt = Path(output_dir) / f\"{img_path.stem}.txt\"\n",
        "\n",
        "    with open(output_txt, \"w\") as f:\n",
        "        for result in results:\n",
        "            img_height, img_width = result.orig_shape\n",
        "            boxes = result.boxes.data\n",
        "\n",
        "            if boxes is None or len(boxes) == 0:\n",
        "                continue\n",
        "\n",
        "            # 🎯 For multi-instance detection: sort by confidence, keep top 2 detections\n",
        "            sorted_boxes = sorted(boxes.tolist(), key=lambda x: x[4], reverse=True)[:2]\n",
        "\n",
        "            for box in sorted_boxes:\n",
        "                x1, y1, x2, y2, conf, cls_id = box\n",
        "\n",
        "                # Skip boxes with confidence below threshold\n",
        "                if conf < conf_threshold:\n",
        "                    continue\n",
        "\n",
        "                # Convert to YOLO format (normalized)\n",
        "                x_center = ((x1 + x2) / 2) / img_width\n",
        "                y_center = ((y1 + y2) / 2) / img_height\n",
        "                width = (x2 - x1) / img_width\n",
        "                height = (y2 - y1) / img_height\n",
        "\n",
        "                # Save in format: class_id confidence x_center y_center width height\n",
        "                f.write(f\"{int(cls_id)} {conf:.6f} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "\n",
        "print(f\"✅ All prediction labels saved to: {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y5uKKRYSYCq",
        "outputId": "9ae13ef5-cccb-411b-b6bb-433c838005d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📝 Generating optimized prediction labels...\n",
            "✅ All prediction labels saved to: /content/submission\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import csv\n",
        "\n",
        "print(\"📊 Generating the final submission file...\")\n",
        "\n",
        "def create_optimized_submission(\n",
        "    preds_folder: str = \"/content/submission\",\n",
        "    output_csv: str = \"/kaggle/working/optimized_submission.csv\",\n",
        "    test_images_folder: str = \"/kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/TestImages/images\",\n",
        "    allowed_extensions: tuple = (\".jpg\", \".png\", \".jpeg\")\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate a submission CSV file from prediction text files.\n",
        "\n",
        "    Args:\n",
        "        preds_folder (str): Folder containing YOLO prediction .txt files.\n",
        "        output_csv (str): Path to save the final submission CSV.\n",
        "        test_images_folder (str): Folder containing the test images.\n",
        "        allowed_extensions (tuple): Allowed image file types.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The final submission DataFrame.\n",
        "    \"\"\"\n",
        "    preds_path = Path(preds_folder)\n",
        "    test_images_path = Path(test_images_folder)\n",
        "\n",
        "    # Get all test image names without extension\n",
        "    test_images = {p.stem for p in test_images_path.glob(\"*\") if p.suffix.lower() in allowed_extensions}\n",
        "\n",
        "    predictions = []\n",
        "    predicted_images = set()\n",
        "    stats = {\"with_predictions\": 0, \"no_predictions\": 0}\n",
        "\n",
        "    # Read predictions from .txt files\n",
        "    for txt_file in preds_path.glob(\"*.txt\"):\n",
        "        image_id = txt_file.stem\n",
        "        predicted_images.add(image_id)\n",
        "\n",
        "        with open(txt_file, \"r\") as f:\n",
        "            valid_lines = [line.strip() for line in f if len(line.strip().split()) == 6]\n",
        "\n",
        "        if valid_lines:\n",
        "            pred_str = \" \".join(valid_lines)\n",
        "            stats[\"with_predictions\"] += 1\n",
        "        else:\n",
        "            pred_str = \"no boxes\"\n",
        "            stats[\"no_predictions\"] += 1\n",
        "\n",
        "        predictions.append({\"image_id\": image_id, \"prediction_string\": pred_str})\n",
        "\n",
        "    # Handle images that have no prediction file\n",
        "    missing_images = test_images - predicted_images\n",
        "    for image_id in missing_images:\n",
        "        predictions.append({\"image_id\": image_id, \"prediction_string\": \"no boxes\"})\n",
        "        stats[\"no_predictions\"] += 1\n",
        "\n",
        "    # Create and sort the submission DataFrame\n",
        "    submission_df = pd.DataFrame(predictions)\n",
        "    submission_df = submission_df.sort_values('image_id')\n",
        "    submission_df.to_csv(output_csv, index=False, quoting=csv.QUOTE_MINIMAL)\n",
        "\n",
        "    # Print stats\n",
        "    print(f\"📈 Submission Stats:\")\n",
        "    print(f\"   Images with predictions: {stats['with_predictions']}\")\n",
        "    print(f\"   Images without predictions: {stats['no_predictions']}\")\n",
        "    print(f\"   Total images: {len(predictions)}\")\n",
        "    print(f\"✅ Submission saved to: {output_csv}\")\n",
        "\n",
        "    return submission_df\n",
        "\n",
        "# Generate the submission file\n",
        "submission_df = create_optimized_submission()\n",
        "\n",
        "# Preview the submission file\n",
        "print(\"\\n📋 Submission Preview:\")\n",
        "print(submission_df.head(10))\n",
        "print(f\"\\nSubmission file shape: {submission_df.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "jXhGY-guSazS",
        "outputId": "9a94057d-c477-426f-a5db-ff433821369f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Generating the final submission file...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'image_id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3046933648>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Generate the submission file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0msubmission_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_optimized_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Preview the submission file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-3046933648>\u001b[0m in \u001b[0;36mcreate_optimized_submission\u001b[0;34m(preds_folder, output_csv, test_images_folder, allowed_extensions)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Create and sort the submission DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0msubmission_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0msubmission_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmission_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0msubmission_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUOTE_MINIMAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7187\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7189\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7191\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'image_id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: /content/submission_from_results.csv make it a data fram\n",
        "\n",
        "submission_df = pd.read_csv('/content/submission_from_results.csv')\n",
        "print(submission_df.head())\n",
        "print(submission_df.info())\n",
        "submission_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XONCwHpWLbh",
        "outputId": "db9ad332-119c-439e-d2b5-b8dde1b4cc26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   image_id                                  prediction_string\n",
            "0  IMG_9562  0 0.941095 0.282437 0.276353 0.077895 0.148537...\n",
            "1  IMG_9563  0 0.880785 0.525480 0.579491 0.326818 0.345432...\n",
            "2  IMG_9564  0 0.909203 0.481050 0.462901 0.228213 0.299315...\n",
            "3  IMG_9565  0 0.853321 0.697713 0.189408 0.126730 0.127765...\n",
            "4  IMG_9566  0 0.970180 0.358000 0.628993 0.126587 0.223958...\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 179 entries, 0 to 178\n",
            "Data columns (total 2 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   image_id           179 non-null    object\n",
            " 1   prediction_string  177 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 2.9+ KB\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(179, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.read_csv(\"/content/submission.csv\")\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2099
        },
        "id": "6rKuko0XXbpR",
        "outputId": "8f666386-3da1-4b13-fbb3-5fc09e6b74e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     image_id                                  prediction_string\n",
              "0    IMG_9757  0 0.897171 0.577790 0.301068 0.054396 0.103128...\n",
              "1    IMG_9792  0 0.929153 0.583613 0.751287 0.079941 0.145574...\n",
              "2    IMG_9607  0 0.949492 0.690762 0.471921 0.175357 0.169644...\n",
              "3    IMG_9567  0 0.949058 0.763976 0.492270 0.137844 0.136842...\n",
              "4    IMG_9769     0 0.830970 0.294869 0.577469 0.270854 0.676866\n",
              "..        ...                                                ...\n",
              "174  IMG_9711  0 0.789559 0.395058 0.715779 0.057419 0.123681...\n",
              "175  IMG_9759  0 0.912956 0.433836 0.385901 0.134016 0.276545...\n",
              "176  IMG_9681     0 0.852444 0.418380 0.390726 0.121050 0.116531\n",
              "177  IMG_9712  0 0.914191 0.328707 0.546428 0.065769 0.140778...\n",
              "178  IMG_9763  0 0.929926 0.625593 0.373147 0.075293 0.141339...\n",
              "\n",
              "[179 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c0f85eb-b1f6-4975-9f0d-c16d856c370d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>prediction_string</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IMG_9757</td>\n",
              "      <td>0 0.897171 0.577790 0.301068 0.054396 0.103128...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IMG_9792</td>\n",
              "      <td>0 0.929153 0.583613 0.751287 0.079941 0.145574...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IMG_9607</td>\n",
              "      <td>0 0.949492 0.690762 0.471921 0.175357 0.169644...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IMG_9567</td>\n",
              "      <td>0 0.949058 0.763976 0.492270 0.137844 0.136842...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IMG_9769</td>\n",
              "      <td>0 0.830970 0.294869 0.577469 0.270854 0.676866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>IMG_9711</td>\n",
              "      <td>0 0.789559 0.395058 0.715779 0.057419 0.123681...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>IMG_9759</td>\n",
              "      <td>0 0.912956 0.433836 0.385901 0.134016 0.276545...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>IMG_9681</td>\n",
              "      <td>0 0.852444 0.418380 0.390726 0.121050 0.116531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>IMG_9712</td>\n",
              "      <td>0 0.914191 0.328707 0.546428 0.065769 0.140778...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>IMG_9763</td>\n",
              "      <td>0 0.929926 0.625593 0.373147 0.075293 0.141339...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>179 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c0f85eb-b1f6-4975-9f0d-c16d856c370d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c0f85eb-b1f6-4975-9f0d-c16d856c370d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c0f85eb-b1f6-4975-9f0d-c16d856c370d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ea691a3a-48bf-40f6-aa13-a4d8eadfd01c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea691a3a-48bf-40f6-aa13-a4d8eadfd01c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ea691a3a-48bf-40f6-aa13-a4d8eadfd01c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_aa8a24d4-208f-4280-b2a7-411632bd3604\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_aa8a24d4-208f-4280-b2a7-411632bd3604 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x",
              "summary": "{\n  \"name\": \"x\",\n  \"rows\": 179,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 179,\n        \"samples\": [\n          \"IMG_9713\",\n          \"IMG_9583\",\n          \"IMG_9744\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prediction_string\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 177,\n        \"samples\": [\n          \"0 0.898555 0.452142 0.984833 0.054800 0.030333 0 0.822853 0.338108 0.807991 0.046191 0.065784 0 0.762606 0.401084 0.929006 0.075591 0.139491 0 0.629074 0.372684 0.854430 0.050335 0.088764 0 0.612489 0.382092 0.788441 0.041876 0.054124 0 0.601353 0.218348 0.755783 0.045546 0.054754 0 0.490954 0.207357 0.742765 0.068044 0.081467 0 0.447121 0.324233 0.855796 0.047911 0.060865 0 0.417878 0.458059 0.400835 0.217744 0.214168 0 0.377286 0.051846 0.960343 0.103692 0.077195 0 0.375563 0.677691 0.260897 0.097664 0.213051 0 0.272123 0.275964 0.875129 0.051664 0.059099\",\n          \"0 0.948596 0.342959 0.589941 0.180250 0.207123 0 0.930041 0.581809 0.412564 0.065980 0.143183\",\n          \"0 0.951792 0.624375 0.674435 0.151627 0.179926 0 0.921332 0.137908 0.664613 0.170316 0.340669\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: fill all the nulls in the submission with 0 and then download it\n",
        "\n",
        "# Assuming 'submission_df' is already loaded and represents the submission data.\n",
        "# Fill all null values in the DataFrame with 0\n",
        "submission_df = submission_df.fillna(0)\n",
        "\n",
        "# If the requirement is to fill empty strings in 'prediction_string' with 0 specifically,\n",
        "# which is an unusual format for this type of submission, use the line below instead of the previous one.\n",
        "# However, based on common competition formats, filling nulls with 0 and keeping empty strings as they are is more likely.\n",
        "# If the intention is to replace the *text* \"no boxes\" or *empty strings* with the *string* \"0\", adjust accordingly.\n",
        "# Let's stick to filling actual nulls with 0 as per the direct request \"fill all the nulls... with 0\".\n",
        "# submission_df['prediction_string'] = submission_df['prediction_string'].replace('', '0') # Use this if empty string should become \"0\"\n",
        "\n",
        "print(\"\\nDataFrame after filling null values with 0:\")\n",
        "print(submission_df.isnull().sum())\n",
        "print((submission_df['prediction_string'] == '').sum()) # Check if any empty strings remain (if they were not nulls)\n",
        "\n",
        "# Save the updated submission DataFrame to a CSV file\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"\\nSubmission file 'submission.csv' updated after filling nulls with 0.\")\n",
        "print(submission_df.head())\n",
        "\n",
        "# Download the updated submission file\n",
        "files.download('submission.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtmSBW_QWgcr",
        "outputId": "39f17b1e-f3e5-47f6-ca62-b721fe6d9dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after filling missing values:\n",
            "image_id             0\n",
            "prediction_string    0\n",
            "dtype: int64\n",
            "0\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: rechick it\n",
        "\n",
        "submission_df = submission_df.fillna('') # Use empty string for missing predictions\n",
        "print(\"\\nDataFrame after filling missing values with empty string:\")\n",
        "print(submission_df.isnull().sum())\n",
        "print((submission_df['prediction_string'] == '').sum())\n",
        "print((submission_df['prediction_string'] == 'no boxes').sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDxEcovrWswS",
        "outputId": "d1d2574d-8fe1-41cf-98ad-45d9f83c8643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after filling missing values with empty string:\n",
            "image_id             0\n",
            "prediction_string    0\n",
            "dtype: int64\n",
            "0\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp8FlnD1Wxch",
        "outputId": "8af67286-66e8-479b-c3b3-a83b95162fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 179 entries, 0 to 178\n",
            "Data columns (total 2 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   image_id           179 non-null    object\n",
            " 1   prediction_string  179 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 2.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2363
        },
        "id": "W9X8PnBQW1m1",
        "outputId": "aa0abe5a-7f02-4a62-d6b2-9bd2b608586e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     image_id                                  prediction_string\n",
              "0    IMG_9562  0 0.941095 0.282437 0.276353 0.077895 0.148537...\n",
              "1    IMG_9563  0 0.880785 0.525480 0.579491 0.326818 0.345432...\n",
              "2    IMG_9564  0 0.909203 0.481050 0.462901 0.228213 0.299315...\n",
              "3    IMG_9565  0 0.853321 0.697713 0.189408 0.126730 0.127765...\n",
              "4    IMG_9566  0 0.970180 0.358000 0.628993 0.126587 0.223958...\n",
              "..        ...                                                ...\n",
              "174  IMG_9788  0 0.949936 0.338021 0.488660 0.079062 0.165912...\n",
              "175  IMG_9789  0 0.943173 0.307385 0.809598 0.077558 0.210937...\n",
              "176  IMG_9790  0 0.922041 0.204219 0.405568 0.137591 0.202998...\n",
              "177  IMG_9791  0 0.949616 0.478764 0.792190 0.091092 0.215915...\n",
              "178  IMG_9792  0 0.929153 0.583613 0.751287 0.079941 0.145574...\n",
              "\n",
              "[179 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-683e8009-a4ff-4dcf-adde-206fbd12edb6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>prediction_string</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IMG_9562</td>\n",
              "      <td>0 0.941095 0.282437 0.276353 0.077895 0.148537...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IMG_9563</td>\n",
              "      <td>0 0.880785 0.525480 0.579491 0.326818 0.345432...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IMG_9564</td>\n",
              "      <td>0 0.909203 0.481050 0.462901 0.228213 0.299315...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IMG_9565</td>\n",
              "      <td>0 0.853321 0.697713 0.189408 0.126730 0.127765...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IMG_9566</td>\n",
              "      <td>0 0.970180 0.358000 0.628993 0.126587 0.223958...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>IMG_9788</td>\n",
              "      <td>0 0.949936 0.338021 0.488660 0.079062 0.165912...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>IMG_9789</td>\n",
              "      <td>0 0.943173 0.307385 0.809598 0.077558 0.210937...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>IMG_9790</td>\n",
              "      <td>0 0.922041 0.204219 0.405568 0.137591 0.202998...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>IMG_9791</td>\n",
              "      <td>0 0.949616 0.478764 0.792190 0.091092 0.215915...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>IMG_9792</td>\n",
              "      <td>0 0.929153 0.583613 0.751287 0.079941 0.145574...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>179 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-683e8009-a4ff-4dcf-adde-206fbd12edb6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-683e8009-a4ff-4dcf-adde-206fbd12edb6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-683e8009-a4ff-4dcf-adde-206fbd12edb6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dedaf5f4-b637-421b-a195-29f32ec4e0aa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dedaf5f4-b637-421b-a195-29f32ec4e0aa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dedaf5f4-b637-421b-a195-29f32ec4e0aa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4630e2b2-c292-40b1-a6c3-58a740582dcc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('submission_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4630e2b2-c292-40b1-a6c3-58a740582dcc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('submission_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submission_df",
              "summary": "{\n  \"name\": \"submission_df\",\n  \"rows\": 179,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 179,\n        \"samples\": [\n          \"IMG_9681\",\n          \"IMG_9578\",\n          \"IMG_9627\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prediction_string\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 178,\n        \"samples\": [\n          \"0 0.931355 0.391562 0.290870 0.045886 0.081111 0 0.895712 0.448248 0.467832 0.103438 0.101156 0 0.789161 0.748005 0.830391 0.205968 0.338639 0 0.760003 0.438162 0.782532 0.032661 0.042445\",\n          \"0 0.949492 0.690762 0.471921 0.175357 0.169644 0 0.897882 0.524640 0.110036 0.065304 0.163070 0 0.314960 0.180715 0.595303 0.198770 0.237806\",\n          \"0 0.966485 0.727514 0.633873 0.126253 0.259380 0 0.940533 0.843038 0.909212 0.153893 0.180296 0 0.903229 0.490890 0.560245 0.066590 0.146590 0 0.823772 0.288050 0.970157 0.069236 0.059687 0 0.309226 0.477273 0.547126 0.043831 0.118452\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "95ff8231355d469dac978daf3b17fbfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c7548a0f98549888e5839cc95e42ae9"
            ],
            "layout": "IPY_MODEL_48b75d859c8a4b0a91110122a42039f8"
          }
        },
        "e2aef9f8af4b4551930af1ac9736c0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c64f5f240f9a499bb791f08b333fcc5d",
            "placeholder": "​",
            "style": "IPY_MODEL_73a5cae09efb4416b9acd90efdf7a579",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "594bfb9ca0b74215ae51d855cab41543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_3de5d68a4140453b9fa3ede86b3ee03c",
            "placeholder": "​",
            "style": "IPY_MODEL_7043e8082d3c4d22855b2b49b002c15e",
            "value": "muhammadgalal"
          }
        },
        "195ac721cc2943a2bf3d9feb6eff13ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6a4dc9a77ad8447d97680a5eac1cd101",
            "placeholder": "​",
            "style": "IPY_MODEL_532fa79484184437b316ecacd284b064",
            "value": ""
          }
        },
        "55e89285237c427e94b4990f3abb72a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a456dfaabf654423aebdc6f2fc2169ba",
            "style": "IPY_MODEL_405b177152704226875e5b5b6c4b0777",
            "tooltip": ""
          }
        },
        "8fea3e7b085646d39fd891752a702f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dddacd303364716b932003ca3a2096a",
            "placeholder": "​",
            "style": "IPY_MODEL_70b9f53c894c419db4225c6c35e74ffd",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "48b75d859c8a4b0a91110122a42039f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "c64f5f240f9a499bb791f08b333fcc5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73a5cae09efb4416b9acd90efdf7a579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3de5d68a4140453b9fa3ede86b3ee03c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7043e8082d3c4d22855b2b49b002c15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a4dc9a77ad8447d97680a5eac1cd101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "532fa79484184437b316ecacd284b064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a456dfaabf654423aebdc6f2fc2169ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "405b177152704226875e5b5b6c4b0777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "0dddacd303364716b932003ca3a2096a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b9f53c894c419db4225c6c35e74ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82ccbf6c819d4c84bd7c912e828e462b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c3b768ace874bdd9816d52dbb9194d8",
            "placeholder": "​",
            "style": "IPY_MODEL_2eadb763c06d436bb9dd12dd2c1da453",
            "value": "Connecting..."
          }
        },
        "1c3b768ace874bdd9816d52dbb9194d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eadb763c06d436bb9dd12dd2c1da453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c7548a0f98549888e5839cc95e42ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeaa7dcfff6b4507ac1a46f97f36df44",
            "placeholder": "​",
            "style": "IPY_MODEL_c2c20b7ab813430bafccd70da6e14469",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "aeaa7dcfff6b4507ac1a46f97f36df44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c20b7ab813430bafccd70da6e14469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}